import streamlit as st
import google.generativeai as genai
import json

st.set_page_config(
    page_title="ì§ˆë¬¸ ë¶„ë¥˜ ë„ìš°ë¯¸",
    page_icon="ğŸ“",
    layout="wide"
)

st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #6B7280;
        text-align: center;
        margin-bottom: 2rem;
    }
    .bloom-tag {
        display: inline-block;
        padding: 0.3rem 0.8rem;
        border-radius: 20px;
        font-size: 0.85rem;
        font-weight: 600;
        margin: 0.2rem;
    }
    .relevant { background-color: #10B981; color: white; }
    .irrelevant { background-color: #EF4444; color: white; }
    .bloom-remember { background-color: #F59E0B; }
    .bloom-understand { background-color: #3B82F6; }
    .bloom-apply { background-color: #8B5CF6; }
    .bloom-analyze { background-color: #EC4899; }
    .bloom-evaluate { background-color: #14B8A6; }
    .bloom-create { background-color: #F97316; }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def init_gemini():
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    model = genai.GenerativeModel(
        model_name="gemini-2.5-flash",
        generation_config={
            "temperature": 0.7,
            "top_p": 0.95,
            "max_output_tokens": 8192,
        }
    )
    return model

CLASSIFICATION_PROMPT = '''ë‹¹ì‹ ì€ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•™ìƒì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”.

## êµìœ¡ê³¼ì • ì •ë³´
{curriculum}

## í•™ìƒ ì§ˆë¬¸
"{question}"

## ë¶„ì„ ìš”ì²­
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ì‘ë‹µí•˜ì„¸ìš”:

{
    "relevance": {
        "is_relevant": true,
        "reason": "ê´€ë ¨ì„± íŒë‹¨ ì´ìœ "
    },
    "bloom_taxonomy": {
        "level": "ê¸°ì–µ/ì´í•´/ì ìš©/ë¶„ì„/í‰ê°€/ì°½ì¡° ì¤‘ í•˜ë‚˜",
        "explanation": "í•´ë‹¹ ìˆ˜ì¤€ìœ¼ë¡œ ë¶„ë¥˜í•œ ì´ìœ "
    },
    "question_quality": {
        "score": 3,
        "feedback": "ì§ˆë¬¸ì˜ ì§ˆì— ëŒ€í•œ í”¼ë“œë°±"
    }
}

JSONë§Œ ì¶œë ¥í•˜ê³  ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.'''

LEARNING_PATH_PROMPT = '''ë‹¹ì‹ ì€ êµìœ¡ê³¼ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•™ìƒì˜ ì§ˆë¬¸ì„ í•´ê²°í•˜ê¸° ìœ„í•œ í•™ìŠµ ê²½ë¡œë¥¼ ì œì‹œí•˜ì„¸ìš”.

## êµìœ¡ê³¼ì • ì •ë³´
{curriculum}

## í•™ìƒ ì§ˆë¬¸
"{question}"

## ìš”ì²­ì‚¬í•­
ì´ ì§ˆë¬¸ì„ í•´ê²°í•˜ê¸° ìœ„í•´ í•™ìƒì´ ë°°ì›Œì•¼ í•  ë‚´ìš©ì„ êµìœ¡ê³¼ì •ì„ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

### ğŸ“š í•„ìˆ˜ ì„ ìˆ˜ ì§€ì‹
(ì´ ì§ˆë¬¸ì„ ì´í•´í•˜ê¸° ìœ„í•´ ë¨¼ì € ì•Œì•„ì•¼ í•  ê°œë…ë“¤)

### ğŸ¯ í•µì‹¬ í•™ìŠµ ë‚´ìš©
(ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ëœ êµìœ¡ê³¼ì • ë‚´ìš©)

### ğŸ”— ì—°ê³„ í•™ìŠµ ì£¼ì œ
(ì§ˆë¬¸ì„ í™•ì¥í•˜ì—¬ ë” ê¹Šì´ ë°°ìš¸ ìˆ˜ ìˆëŠ” ë‚´ìš©)

### ğŸ’¡ ì¶”ì²œ í•™ìŠµ í™œë™
(ì´ ì§ˆë¬¸ì„ íƒêµ¬í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ í™œë™ ì œì•ˆ)

### ğŸ“– ì°¸ê³ í•  êµìœ¡ê³¼ì • ì„±ì·¨ê¸°ì¤€
(ê´€ë ¨ëœ ì„±ì·¨ê¸°ì¤€ ë‚˜ì—´)'''

if "messages" not in st.session_state:
    st.session_state.messages = []
if "questions_history" not in st.session_state:
    st.session_state.questions_history = []
if "curriculum" not in st.session_state:
    st.session_state.curriculum = ""

with st.sidebar:
    st.markdown("## ğŸ“‹ êµìœ¡ê³¼ì • ì„¤ì •")
    
    curriculum_input = st.text_area(
        "êµìœ¡ê³¼ì • ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”",
        value=st.session_state.curriculum,
        height=300,
        placeholder="ì˜ˆì‹œ:\n[ê³¼ëª©] ì´ˆë“±í•™êµ 5í•™ë…„ ê³¼í•™\n[ë‹¨ì›] íƒœì–‘ê³„ì™€ ë³„\n[ì„±ì·¨ê¸°ì¤€]\n- íƒœì–‘ì´ ì§€êµ¬ì˜ ì—ë„ˆì§€ì›ì„ì„ ì´í•´í•œë‹¤."
    )
    
    if st.button("âœ… êµìœ¡ê³¼ì • ì €ì¥", use_container_width=True):
        st.session_state.curriculum = curriculum_input
        st.success("êµìœ¡ê³¼ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    st.divider()
    
    st.markdown("## ğŸ“ Bloom's Taxonomy")
    st.markdown("""
| ìˆ˜ì¤€ | ì„¤ëª… |
|------|------|
| ğŸŸ¡ **ê¸°ì–µ** | ì‚¬ì‹¤, ìš©ì–´ íšŒìƒ |
| ğŸ”µ **ì´í•´** | ì˜ë¯¸ íŒŒì•…, ì„¤ëª… |
| ğŸŸ£ **ì ìš©** | ìƒˆë¡œìš´ ìƒí™©ì— ì ìš© |
| ğŸ©· **ë¶„ì„** | êµ¬ì„±ìš”ì†Œ ë¶„í•´ |
| ğŸ©µ **í‰ê°€** | íŒë‹¨, ë¹„í‰ |
| ğŸŸ  **ì°½ì¡°** | ìƒˆë¡œìš´ ê²ƒ ìƒì„± |
    """)
    
    st.divider()
    
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.messages = []
        st.session_state.questions_history = []
        st.rerun()

st.markdown('<h1 class="main-header">ğŸ“ ì§ˆë¬¸ ë¶„ë¥˜ ë„ìš°ë¯¸</h1>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">í•™ìƒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  í•™ìŠµ ê²½ë¡œë¥¼ ì œì‹œí•©ë‹ˆë‹¤</p>', unsafe_allow_html=True)

if not st.session_state.curriculum:
    st.warning("âš ï¸ ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ êµìœ¡ê³¼ì •ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

tab1, tab2 = st.tabs(["ğŸ’¬ ì§ˆë¬¸ ë¶„ì„", "ğŸ“Š ì§ˆë¬¸ ê¸°ë¡"])

with tab1:
    chat_container = st.container()
    
    with chat_container:
        for msg in st.session_state.messages:
            if msg["role"] == "user":
                with st.chat_message("user", avatar="ğŸ‘¨â€ğŸ“"):
                    st.markdown(msg["content"])
            else:
                with st.chat_message("assistant", avatar="ğŸ¤–"):
                    st.markdown(msg["content"], unsafe_allow_html=True)
    
    user_question = st.chat_input("í•™ìƒ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
    
    if user_question and st.session_state.curriculum:
        st.session_state.messages.append({"role": "user", "content": user_question})
        
        with st.chat_message("user", avatar="ğŸ‘¨â€ğŸ“"):
            st.markdown(user_question)
        
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            with st.spinner("ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                try:
                    model = init_gemini()
                    
                    classification_prompt = CLASSIFICATION_PROMPT.format(
                        curriculum=st.session_state.curriculum,
                        question=user_question
                    )
                    
                    response = model.generate_content(classification_prompt)
                    response_text = response.text.strip()
                    
                    if "```json" in response_text:
                        json_str = response_text.split("```json")[1].split("```")[0]
                    elif "```" in response_text:
                        json_str = response_text.split("```")[1].split("```")[0]
                    else:
                        json_str = response_text
                    
                    analysis = json.loads(json_str.strip())
                    
                    relevance = analysis.get("relevance", {})
                    bloom = analysis.get("bloom_taxonomy", {})
                    quality = analysis.get("question_quality", {})
                    
                    is_relevant = relevance.get("is_relevant", False)
                    relevance_class = "relevant" if is_relevant else "irrelevant"
                    relevance_text = "âœ… ìˆ˜ì—… ê´€ë ¨" if is_relevant else "âŒ ìˆ˜ì—… ë¬´ê´€"
                    
                    bloom_level = bloom.get("level", "ë¯¸ë¶„ë¥˜")
                    bloom_colors = {
                        "ê¸°ì–µ": "bloom-remember",
                        "ì´í•´": "bloom-understand", 
                        "ì ìš©": "bloom-apply",
                        "ë¶„ì„": "bloom-analyze",
                        "í‰ê°€": "bloom-evaluate",
                        "ì°½ì¡°": "bloom-create"
                    }
                    bloom_class = bloom_colors.get(bloom_level, "bloom-remember")
                    
                    score = quality.get("score", 3)
                    stars = "â­" * score
                    
                    result_html = f'''### ğŸ“Š ì§ˆë¬¸ ë¶„ì„ ê²°ê³¼

<span class="bloom-tag {relevance_class}">{relevance_text}</span>
<span class="bloom-tag {bloom_class}">Bloom: {bloom_level}</span>
<span class="bloom-tag" style="background-color: #6366F1; color: white;">í’ˆì§ˆ: {stars}</span>

**ğŸ“Œ ê´€ë ¨ì„± ë¶„ì„**
> {relevance.get("reason", "ë¶„ì„ ì¤‘...")}

**ğŸ¯ Bloom taxonomy ë¶„ë¥˜**
> {bloom.get("explanation", "ë¶„ì„ ì¤‘...")}

**ğŸ’¬ ì§ˆë¬¸ í”¼ë“œë°±**
> {quality.get("feedback", "ë¶„ì„ ì¤‘...")}'''
                    
                    st.markdown(result_html, unsafe_allow_html=True)
                    
                    if is_relevant:
                        if st.button("ğŸ“š í•™ìŠµ ê²½ë¡œ ë³´ê¸°", key=f"path_{len(st.session_state.messages)}"):
                            with st.spinner("í•™ìŠµ ê²½ë¡œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                                learning_prompt = LEARNING_PATH_PROMPT.format(
                                    curriculum=st.session_state.curriculum,
                                    question=user_question
                                )
                                learning_response = model.generate_content(learning_prompt)
                                st.markdown("---")
                                st.markdown(learning_response.text)
                    
                    st.session_state.questions_history.append({
                        "question": user_question,
                        "is_relevant": is_relevant,
                        "bloom_level": bloom_level,
                        "score": score,
                        "analysis": analysis
                    })
                    
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": result_html
                    })
                    
                except json.JSONDecodeError as e:
                    st.error(f"ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
                    st.code(response_text)
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

with tab2:
    if st.session_state.questions_history:
        st.markdown("### ğŸ“‹ ë¶„ì„ëœ ì§ˆë¬¸ ëª©ë¡")
        
        col1, col2 = st.columns(2)
        with col1:
            filter_relevance = st.selectbox(
                "ê´€ë ¨ì„± í•„í„°",
                ["ì „ì²´", "ìˆ˜ì—… ê´€ë ¨", "ìˆ˜ì—… ë¬´ê´€"]
            )
        with col2:
            filter_bloom = st.selectbox(
                "Bloom ìˆ˜ì¤€ í•„í„°",
                ["ì „ì²´", "ê¸°ì–µ", "ì´í•´", "ì ìš©", "ë¶„ì„", "í‰ê°€", "ì°½ì¡°"]
            )
        
        filtered = st.session_state.questions_history.copy()
        
        if filter_relevance == "ìˆ˜ì—… ê´€ë ¨":
            filtered = [q for q in filtered if q["is_relevant"]]
        elif filter_relevance == "ìˆ˜ì—… ë¬´ê´€":
            filtered = [q for q in filtered if not q["is_relevant"]]
            
        if filter_bloom != "ì „ì²´":
            filtered = [q for q in filtered if q["bloom_level"] == filter_bloom]
        
        for i, q in enumerate(filtered):
            with st.expander(f"{'âœ…' if q['is_relevant'] else 'âŒ'} {q['question'][:50]}..."):
                st.markdown(f"**ì§ˆë¬¸:** {q['question']}")
                st.markdown(f"**Bloom ìˆ˜ì¤€:** {q['bloom_level']}")
                st.markdown(f"**í’ˆì§ˆ ì ìˆ˜:** {'â­' * q['score']}")
                
                if q["is_relevant"]:
                    if st.button("ğŸ“š ì´ ì§ˆë¬¸ì˜ í•™ìŠµ ê²½ë¡œ ìƒì„±", key=f"history_{i}"):
                        with st.spinner("í•™ìŠµ ê²½ë¡œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                            model = init_gemini()
                            learning_prompt = LEARNING_PATH_PROMPT.format(
                                curriculum=st.session_state.curriculum,
                                question=q["question"]
                            )
                            learning_response = model.generate_content(learning_prompt)
                            st.markdown("---")
                            st.markdown(learning_response.text)
        
        st.markdown("---")
        st.markdown("### ğŸ“ˆ ì§ˆë¬¸ í†µê³„")
        
        total = len(st.session_state.questions_history)
        relevant = sum(1 for q in st.session_state.questions_history if q["is_relevant"])
        
        col1, col2, col3 = st.columns(3)
        col1.metric("ì´ ì§ˆë¬¸ ìˆ˜", total)
        col2.metric("ìˆ˜ì—… ê´€ë ¨ ì§ˆë¬¸", relevant)
        col3.metric("ê´€ë ¨ì„± ë¹„ìœ¨", f"{(relevant/total*100):.1f}%" if total > 0 else "0%")
        
        bloom_counts = {}
        for q in st.session_state.questions_history:
            level = q["bloom_level"]
            bloom_counts[level] = bloom_counts.get(level, 0) + 1
        
        if bloom_counts:
            st.markdown("#### Bloom's Taxonomy ë¶„í¬")
            for level, count in sorted(bloom_counts.items()):
                st.progress(count/total, text=f"{level}: {count}ê°œ ({count/total*100:.1f}%)")
    
    else:
        st.info("ì•„ì§ ë¶„ì„ëœ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. 'ì§ˆë¬¸ ë¶„ì„' íƒ­ì—ì„œ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

st.markdown("---")
st.markdown(
    "<p style='text-align: center; color: #9CA3AF;'>ğŸ“ êµìœ¡ê³¼ì • ê¸°ë°˜ ì§ˆë¬¸ ë¶„ë¥˜ ì‹œìŠ¤í…œ | Powered by Gemini 2.5 Flash</p>",
    unsafe_allow_html=True
)
