import streamlit as st
import google.generativeai as genai
import json
import re

st.set_page_config(
    page_title="ì§ˆë¬¸ ë¶„ë¥˜ ë„ìš°ë¯¸",
    page_icon="ğŸ“",
    layout="wide"
)

st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: 700;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #6B7280;
        text-align: center;
        margin-bottom: 2rem;
    }
    .bloom-tag {
        display: inline-block;
        padding: 0.3rem 0.8rem;
        border-radius: 20px;
        font-size: 0.85rem;
        font-weight: 600;
        margin: 0.2rem;
    }
    .relevant { background-color: #10B981; color: white; }
    .irrelevant { background-color: #EF4444; color: white; }
    .bloom-remember { background-color: #F59E0B; }
    .bloom-understand { background-color: #3B82F6; }
    .bloom-apply { background-color: #8B5CF6; }
    .bloom-analyze { background-color: #EC4899; }
    .bloom-evaluate { background-color: #14B8A6; }
    .bloom-create { background-color: #F97316; }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def init_gemini():
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    model = genai.GenerativeModel(
        model_name="gemini-2.5-flash",
        generation_config={
            "temperature": 0.3,
            "top_p": 0.95,
            "max_output_tokens": 8192,
        }
    )
    return model

def parse_json_response(response_text):
    text = response_text.strip()
    
    json_match = re.search(r'```json\s*([\s\S]*?)\s*```', text)
    if json_match:
        try:
            return json.loads(json_match.group(1))
        except:
            pass
    
    code_match = re.search(r'```\s*([\s\S]*?)\s*```', text)
    if code_match:
        try:
            return json.loads(code_match.group(1))
        except:
            pass
    
    json_match = re.search(r'\{[\s\S]*\}', text)
    if json_match:
        try:
            return json.loads(json_match.group(0))
        except:
            pass
    
    try:
        return json.loads(text)
    except:
        pass
    
    return None

def get_classification_prompt(curriculum, question):
    return f"""ë‹¹ì‹ ì€ êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•™ìƒì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì„¸ìš”.

[êµìœ¡ê³¼ì •]
{curriculum}

[í•™ìƒ ì§ˆë¬¸]
{question}

[ì§€ì‹œì‚¬í•­]
ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.

{{
    "relevance": {{
        "is_relevant": true,
        "reason": "ì´ ì§ˆë¬¸ì´ êµìœ¡ê³¼ì •ê³¼ ê´€ë ¨ëœ ì´ìœ ë¥¼ ì„¤ëª…"
    }},
    "bloom_taxonomy": {{
        "level": "ê¸°ì–µ",
        "explanation": "ë¸”ë£¸ ë¶„ë¥˜ ìˆ˜ì¤€ ì„ íƒ ì´ìœ "
    }},
    "question_quality": {{
        "score": 3,
        "feedback": "ì§ˆë¬¸ì— ëŒ€í•œ í”¼ë“œë°±"
    }}
}}

- is_relevant: êµìœ¡ê³¼ì •ê³¼ ê´€ë ¨ìˆìœ¼ë©´ true, ì—†ìœ¼ë©´ false
- level: "ê¸°ì–µ", "ì´í•´", "ì ìš©", "ë¶„ì„", "í‰ê°€", "ì°½ì¡°" ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ
- score: 1ë¶€í„° 5 ì‚¬ì´ì˜ ì •ìˆ˜"""

def get_learning_prompt(curriculum, question):
    return f"""ë‹¹ì‹ ì€ êµìœ¡ê³¼ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[êµìœ¡ê³¼ì •]
{curriculum}

[í•™ìƒ ì§ˆë¬¸]
{question}

ì´ ì§ˆë¬¸ì„ í•´ê²°í•˜ê¸° ìœ„í•´ í•™ìƒì´ ë°°ì›Œì•¼ í•  ë‚´ìš©ì„ ì •ë¦¬í•´ì£¼ì„¸ìš”.

### ğŸ“š í•„ìˆ˜ ì„ ìˆ˜ ì§€ì‹

### ğŸ¯ í•µì‹¬ í•™ìŠµ ë‚´ìš©

### ğŸ”— ì—°ê³„ í•™ìŠµ ì£¼ì œ

### ğŸ’¡ ì¶”ì²œ í•™ìŠµ í™œë™

### ğŸ“– ì°¸ê³ í•  êµìœ¡ê³¼ì • ì„±ì·¨ê¸°ì¤€"""

if "messages" not in st.session_state:
    st.session_state.messages = []
if "questions_history" not in st.session_state:
    st.session_state.questions_history = []
if "curriculum" not in st.session_state:
    st.session_state.curriculum = ""

with st.sidebar:
    st.markdown("## ğŸ“‹ êµìœ¡ê³¼ì • ì„¤ì •")
    
    curriculum_input = st.text_area(
        "êµìœ¡ê³¼ì • ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”",
        value=st.session_state.curriculum,
        height=300,
        placeholder="ì˜ˆì‹œ:\n[ê³¼ëª©] ì´ˆë“±í•™êµ 5í•™ë…„ ê³¼í•™\n[ë‹¨ì›] íƒœì–‘ê³„ì™€ ë³„\n[ì„±ì·¨ê¸°ì¤€]\n- íƒœì–‘ì´ ì§€êµ¬ì˜ ì—ë„ˆì§€ì›ì„ì„ ì´í•´í•œë‹¤."
    )
    
    if st.button("âœ… êµìœ¡ê³¼ì • ì €ì¥", use_container_width=True):
        st.session_state.curriculum = curriculum_input
        st.success("êµìœ¡ê³¼ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    st.divider()
    
    st.markdown("## ğŸ“ Bloom's Taxonomy")
    st.markdown("""
| ìˆ˜ì¤€ | ì„¤ëª… |
|------|------|
| ğŸŸ¡ **ê¸°ì–µ** | ì‚¬ì‹¤, ìš©ì–´ íšŒìƒ |
| ğŸ”µ **ì´í•´** | ì˜ë¯¸ íŒŒì•…, ì„¤ëª… |
| ğŸŸ£ **ì ìš©** | ìƒˆë¡œìš´ ìƒí™©ì— ì ìš© |
| ğŸ©· **ë¶„ì„** | êµ¬ì„±ìš”ì†Œ ë¶„í•´ |
| ğŸ©µ **í‰ê°€** | íŒë‹¨, ë¹„í‰ |
| ğŸŸ  **ì°½ì¡°** | ìƒˆë¡œìš´ ê²ƒ ìƒì„± |
    """)
    
    st.divider()
    
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.messages = []
        st.session_state.questions_history = []
        st.rerun()

st.markdown('<h1 class="main-header">ğŸ“ ì§ˆë¬¸ ë¶„ë¥˜ ë„ìš°ë¯¸</h1>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">í•™ìƒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  í•™ìŠµ ê²½ë¡œë¥¼ ì œì‹œí•©ë‹ˆë‹¤</p>', unsafe_allow_html=True)

if not st.session_state.curriculum:
    st.warning("âš ï¸ ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ êµìœ¡ê³¼ì •ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

tab1, tab2 = st.tabs(["ğŸ’¬ ì§ˆë¬¸ ë¶„ì„", "ğŸ“Š ì§ˆë¬¸ ê¸°ë¡"])

with tab1:
    chat_container = st.container()
    
    with chat_container:
        for msg in st.session_state.messages:
            if msg["role"] == "user":
                with st.chat_message("user", avatar="ğŸ‘¨â€ğŸ“"):
                    st.markdown(msg["content"])
            else:
                with st.chat_message("assistant", avatar="ğŸ¤–"):
                    st.markdown(msg["content"], unsafe_allow_html=True)
    
    user_question = st.chat_input("í•™ìƒ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
    
    if user_question and st.session_state.curriculum:
        st.session_state.messages.append({"role": "user", "content": user_question})
        
        with st.chat_message("user", avatar="ğŸ‘¨â€ğŸ“"):
            st.markdown(user_question)
        
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            with st.spinner("ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                try:
                    model = init_gemini()
                    
                    classification_prompt = get_classification_prompt(
                        st.session_state.curriculum,
                        user_question
                    )
                    
                    response = model.generate_content(classification_prompt)
                    response_text = response.text
                    
                    analysis = parse_json_response(response_text)
                    
                    if analysis is None:
                        st.error("JSON íŒŒì‹± ì‹¤íŒ¨. ì›ë³¸ ì‘ë‹µ:")
                        st.code(response_text)
                        st.stop()
                    
                    relevance = analysis.get("relevance", {})
                    bloom = analysis.get("bloom_taxonomy", {})
                    quality = analysis.get("question_quality", {})
                    
                    is_relevant = relevance.get("is_relevant", False)
                    relevance_class = "relevant" if is_relevant else "irrelevant"
                    relevance_text = "âœ… ìˆ˜ì—… ê´€ë ¨" if is_relevant else "âŒ ìˆ˜ì—… ë¬´ê´€"
                    
                    bloom_level = bloom.get("level", "ë¯¸ë¶„ë¥˜")
                    bloom_colors = {
                        "ê¸°ì–µ": "bloom-remember",
                        "ì´í•´": "bloom-understand", 
                        "ì ìš©": "bloom-apply",
                        "ë¶„ì„": "bloom-analyze",
                        "í‰ê°€": "bloom-evaluate",
                        "ì°½ì¡°": "bloom-create"
                    }
                    bloom_class = bloom_colors.get(bloom_level, "bloom-remember")
                    
                    score = quality.get("score", 3)
                    if isinstance(score, str):
                        score = int(score)
                    stars = "â­" * min(max(score, 1), 5)
                    
                    result_html = f"""### ğŸ“Š ì§ˆë¬¸ ë¶„ì„ ê²°ê³¼

<span class="bloom-tag {relevance_class}">{relevance_text}</span>
<span class="bloom-tag {bloom_class}">Bloom: {bloom_level}</span>
<span class="bloom-tag" style="background-color: #6366F1; color: white;">í’ˆì§ˆ: {stars}</span>

**ğŸ“Œ ê´€ë ¨ì„± ë¶„ì„**
> {relevance.get("reason", "ë¶„ì„ ì¤‘...")}

**ğŸ¯ Bloom taxonomy ë¶„ë¥˜**
> {bloom.get("explanation", "ë¶„ì„ ì¤‘...")}

**ğŸ’¬ ì§ˆë¬¸ í”¼ë“œë°±**
> {quality.get("feedback", "ë¶„ì„ ì¤‘...")}"""
                    
                    st.markdown(result_html, unsafe_allow_html=True)
                    
                    if is_relevant:
                        if st.button("ğŸ“š í•™ìŠµ ê²½ë¡œ ë³´ê¸°", key=f"path_{len(st.session_state.messages)}"):
                            with st.spinner("í•™ìŠµ ê²½ë¡œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                                learning_prompt = get_learning_prompt(
                                    st.session_state.curriculum,
                                    user_question
                                )
                                learning_response = model.generate_content(learning_prompt)
                                st.markdown("---")
                                st.markdown(learning_response.text)
                    
                    st.session_state.questions_history.append({
                        "question": user_question,
                        "is_relevant": is_relevant,
                        "bloom_level": bloom_level,
                        "score": score,
                        "analysis": analysis
                    })
                    
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": result_html
                    })
                    
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

with tab2:
    if st.session_state.questions_history:
        st.markdown("### ğŸ“‹ ë¶„ì„ëœ ì§ˆë¬¸ ëª©ë¡")
        
        col1, col2 = st.columns(2)
        with col1:
            filter_relevance = st.selectbox(
                "ê´€ë ¨ì„± í•„í„°",
                ["ì „ì²´", "ìˆ˜ì—… ê´€ë ¨", "ìˆ˜ì—… ë¬´ê´€"]
            )
        with col2:
            filter_bloom = st.selectbox(
                "Bloom ìˆ˜ì¤€ í•„í„°",
                ["ì „ì²´", "ê¸°ì–µ", "ì´í•´", "ì ìš©", "ë¶„ì„", "í‰ê°€", "ì°½ì¡°"]
            )
        
        filtered = st.session_state.questions_history.copy()
        
        if filter_relevance == "ìˆ˜ì—… ê´€ë ¨":
            filtered = [q for q in filtered if q["is_relevant"]]
        elif filter_relevance == "ìˆ˜ì—… ë¬´ê´€":
            filtered = [q for q in filtered if not q["is_relevant"]]
            
        if filter_bloom != "ì „ì²´":
            filtered = [q for q in filtered if q["bloom_level"] == filter_bloom]
        
        for i, q in enumerate(filtered):
            with st.expander(f"{'âœ…' if q['is_relevant'] else 'âŒ'} {q['question'][:50]}..."):
                st.markdown(f"**ì§ˆë¬¸:** {q['question']}")
                st.markdown(f"**Bloom ìˆ˜ì¤€:** {q['bloom_level']}")
                st.markdown(f"**í’ˆì§ˆ ì ìˆ˜:** {'â­' * q['score']}")
                
                if q["is_relevant"]:
                    if st.button("ğŸ“š ì´ ì§ˆë¬¸ì˜ í•™ìŠµ ê²½ë¡œ ìƒì„±", key=f"history_{i}"):
                        with st.spinner("í•™ìŠµ ê²½ë¡œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                            model = init_gemini()
                            learning_prompt = get_learning_prompt(
                                st.session_state.curriculum,
                                q["question"]
                            )
                            learning_response = model.generate_content(learning_prompt)
                            st.markdown("---")
                            st.markdown(learning_response.text)
        
        st.markdown("---")
        st.markdown("### ğŸ“ˆ ì§ˆë¬¸ í†µê³„")
        
        total = len(st.session_state.questions_history)
        relevant = sum(1 for q in st.session_state.questions_history if q["is_relevant"])
        
        col1, col2, col3 = st.columns(3)
        col1.metric("ì´ ì§ˆë¬¸ ìˆ˜", total)
        col2.metric("ìˆ˜ì—… ê´€ë ¨ ì§ˆë¬¸", relevant)
        col3.metric("ê´€ë ¨ì„± ë¹„ìœ¨", f"{(relevant/total*100):.1f}%" if total > 0 else "0%")
        
        bloom_counts = {}
        for q in st.session_state.questions_history:
            level = q["bloom_level"]
            bloom_counts[level] = bloom_counts.get(level, 0) + 1
        
        if bloom_counts:
            st.markdown("#### Bloom's Taxonomy ë¶„í¬")
            for level, count in sorted(bloom_counts.items()):
                st.progress(count/total, text=f"{level}: {count}ê°œ ({count/total*100:.1f}%)")
    
    else:
        st.info("ì•„*
